# Agentic Workflow Example: LLM + Transform
# This pipeline demonstrates an agentic workflow:
# 1. Generate content using an LLM (OpenAI)
# 2. Process/transform the LLM response
# 3. Output the final result

pipelines:
  - name: "Agentic Summary Pipeline"
    description: "Generates a summary using LLM and processes it"
    steps:
      - name: "Generate Summary"
        plugin: "AIModels.openai"
        config:
          operation: "chat"
          model: "gpt-3.5-turbo"
          messages:
            - role: "user"
              content: "Summarize the concept of artificial intelligence in one paragraph."
          max_tokens: 300
          temperature: 0.7
          api_key: "${OPENAI_API_KEY}"  # Use environment variable for API key
        output: "llm_response"

      - name: "Extract Key Points"
        plugin: "Data_Processing.transform"
        config:
          operation: "extract_pattern"
          pattern: "^(.*\\.)$"  # Extract first sentence
          input: "llm_response"
        output: "extracted_summary"

      - name: "Format Output"
        plugin: "Output.json"
        config:
          file_path: "./output/agentic_summary.json"
          input: "extracted_summary"
          pretty: true
        output: "final_result"

# Usage:
# 1. Set OPENAI_API_KEY environment variable
# 2. Run: mimir-aip run test_pipelines/agentic_workflow_example.yaml
# 3. Check output in ./output/agentic_summary.json