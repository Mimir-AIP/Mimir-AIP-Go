# Ontologies

Ontologies will be used to define the entities, attributes and relationships for a specific project(ideally to ensure retrievability and queryability of all data, a project will have a single all encompassing ontology, however we will alllow for multiple ontologies to be used within a project if users want to keep different data separate). Ontologies will be defined using the standard OWL format. When the user has built their ingestion pipeline, mimir will automatically run this, then feed the ingested data into a extraction process(which will be defined below) to extract the entities, attributes and relationships from the ingested data, this will then be used to automatically build the ontology for the project. Additionally if the user prefers they can then manually edit and overide this to either correct any errors, or use an existing ontology they have built elsewhere. This ontology will be used as a basis for how mimir will then structure and process data(e.g. when the ingestion pipelines execute in future and ingest new data, it will be stored in the storage object in the structure defined by the ontology, additionally when building ML models, the ontology will be used to determine what data is available and how it is structured which will inform the model architecture and training process, finally the ontology will also be used when building the digital twin as this will determine what entities, attributes and relationships are represented in the digital twin). To ensure the ontology is always up to date with the ingested data, whenever new data is ingested via the pipelines, mimir will automatically compare the new data with the existing ontology, if it differs mimir will stop and the user will be prompted to either re-run the ontology creation process to update the ontology, or ignore the changes, identifying what extraction failed to correctly identify and what it should have identified instead. This automated re-checking and updating of the ontology will ensure that the ontology always accurately represents the ingested data, which is crucial for ensuring that the data can be effectively used for analysis, ML model training and digital twin creation.