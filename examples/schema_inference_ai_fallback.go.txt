package main

import (
	"context"
	"encoding/json"
	"fmt"
	"log"

	"github.com/Mimir-AIP/Mimir-AIP-Go/pipelines/AI"
	"github.com/Mimir-AIP/Mimir-AIP-Go/pipelines/Ontology/schema_inference"
)

// Example demonstrating AI/LLM fallback in schema inference engine
func main() {
	fmt.Println("=== Schema Inference with AI Fallback Example ===\n")

	// Example 1: Schema inference WITHOUT AI fallback
	runBasicInference()

	// Example 2: Schema inference WITH AI fallback
	runAIEnhancedInference()

	// Example 3: Handling ambiguous data with AI
	runAmbiguousDataInference()
}

// runBasicInference demonstrates traditional deterministic inference
func runBasicInference() {
	fmt.Println("--- Example 1: Basic Deterministic Inference ---")

	// Configure inference engine without AI
	config := schema_inference.InferenceConfig{
		SampleSize:          100,
		ConfidenceThreshold: 0.7,
		EnableRelationships: true,
		EnableConstraints:   true,
		EnableAIFallback:    false, // AI disabled
	}

	engine := schema_inference.NewSchemaInferenceEngine(config)

	// Sample data with clear types
	data := []map[string]interface{}{
		{"id": 1, "name": "John Doe", "age": 30, "email": "john@example.com"},
		{"id": 2, "name": "Jane Smith", "age": 25, "email": "jane@example.com"},
		{"id": 3, "name": "Bob Johnson", "age": 35, "email": "bob@example.com"},
	}

	schema, err := engine.InferSchema(data, "users")
	if err != nil {
		log.Fatalf("Failed to infer schema: %v", err)
	}

	printSchema(schema)
}

// runAIEnhancedInference demonstrates inference with AI fallback
func runAIEnhancedInference() {
	fmt.Println("\n--- Example 2: AI-Enhanced Inference ---")

	// Create a mock LLM client (in production, use real client)
	llmClient := createMockLLMClient()

	// Configure inference engine with AI fallback
	config := schema_inference.InferenceConfig{
		SampleSize:          100,
		ConfidenceThreshold: 0.8, // Higher threshold triggers AI more often
		EnableRelationships: true,
		EnableConstraints:   true,
		EnableAIFallback:    true, // AI enabled
		AIConfidenceBoost:   0.15, // 15% confidence boost from AI
	}

	engine := schema_inference.NewSchemaInferenceEngineWithLLM(config, llmClient)

	// Sample data with ambiguous types (mix of formats)
	data := []map[string]interface{}{
		{"transaction_id": "TXN-001", "amount": "100.50", "status": "completed"},
		{"transaction_id": "TXN-002", "amount": "250.75", "status": "pending"},
		{"transaction_id": "TXN-003", "amount": "75.00", "status": "completed"},
	}

	schema, err := engine.InferSchema(data, "transactions")
	if err != nil {
		log.Fatalf("Failed to infer schema: %v", err)
	}

	printSchema(schema)

	// Check for AI enhancement
	for _, col := range schema.Columns {
		if col.AIEnhanced {
			fmt.Printf("âœ“ Column '%s' was enhanced by AI (confidence: %.2f)\n",
				col.Name, col.AIConfidence)
		}
	}
}

// runAmbiguousDataInference demonstrates AI handling complex semantic types
func runAmbiguousDataInference() {
	fmt.Println("\n--- Example 3: Ambiguous Data with AI ---")

	llmClient := createMockLLMClient()

	config := schema_inference.InferenceConfig{
		SampleSize:          50,
		ConfidenceThreshold: 0.7,
		EnableAIFallback:    true,
		AIConfidenceBoost:   0.2,
	}

	engine := schema_inference.NewSchemaInferenceEngineWithLLM(config, llmClient)

	// Data with complex semantic types
	data := []map[string]interface{}{
		{
			"customer_phone": "+1-555-0123",
			"order_value":    "$1,234.56",
			"delivery_eta":   "2024-01-15T14:30:00Z",
		},
		{
			"customer_phone": "+1-555-0456",
			"order_value":    "$987.65",
			"delivery_eta":   "2024-01-16T10:00:00Z",
		},
	}

	schema, err := engine.InferSchema(data, "orders")
	if err != nil {
		log.Fatalf("Failed to infer schema: %v", err)
	}

	fmt.Println("\nSemantic Type Detection:")
	for _, col := range schema.Columns {
		if semanticType, ok := col.Constraints["semantic_type"].(string); ok {
			fmt.Printf("  %s: %s (semantic: %s)\n", col.Name, col.DataType, semanticType)
		}
	}
}

// createMockLLMClient creates a mock LLM client for demonstration
func createMockLLMClient() AI.LLMClient {
	return &MockLLMClient{}
}

// MockLLMClient is a mock implementation for demonstration
type MockLLMClient struct{}

func (m *MockLLMClient) Complete(ctx context.Context, request AI.LLMRequest) (*AI.LLMResponse, error) {
	// Simulate AI response based on the prompt
	// In production, this would call actual LLM API

	// Parse the column name from the request
	prompt := request.Messages[1].Content

	var response string
	if contains(prompt, "transaction_id") {
		response = `{
			"data_type": "string",
			"ontology_type": "xsd:string",
			"confidence": 0.95,
			"description": "Unique transaction identifier with prefix pattern",
			"constraints": {
				"pattern": "^TXN-[0-9]+$",
				"semantic_type": "transaction_id"
			}
		}`
	} else if contains(prompt, "amount") {
		response = `{
			"data_type": "float",
			"ontology_type": "xsd:decimal",
			"confidence": 0.92,
			"description": "Monetary amount in USD",
			"constraints": {
				"min_value": 0,
				"semantic_type": "currency"
			},
			"domain_suggestions": {
				"semantic_type": "currency",
				"unit": "USD"
			}
		}`
	} else if contains(prompt, "customer_phone") {
		response = `{
			"data_type": "string",
			"ontology_type": "xsd:string",
			"confidence": 0.98,
			"description": "Customer phone number in E.164 format",
			"constraints": {
				"pattern": "^\\+[1-9]\\d{1,14}$",
				"semantic_type": "phone"
			}
		}`
	} else if contains(prompt, "order_value") {
		response = `{
			"data_type": "string",
			"ontology_type": "xsd:string",
			"confidence": 0.88,
			"description": "Formatted currency value with symbol",
			"constraints": {
				"pattern": "^\\$[0-9,]+\\.[0-9]{2}$",
				"semantic_type": "currency"
			}
		}`
	} else {
		response = `{
			"data_type": "string",
			"ontology_type": "xsd:string",
			"confidence": 0.75,
			"description": "General text field"
		}`
	}

	return &AI.LLMResponse{
		Content:      response,
		FinishReason: "stop",
		Model:        "mock-model",
	}, nil
}

func (m *MockLLMClient) CompleteSimple(ctx context.Context, prompt string) (string, error) {
	req := AI.LLMRequest{
		Messages: []AI.LLMMessage{{Role: "user", Content: prompt}},
	}
	resp, err := m.Complete(ctx, req)
	if err != nil {
		return "", err
	}
	return resp.Content, nil
}

func (m *MockLLMClient) GetProvider() AI.LLMProvider {
	return "mock"
}

func (m *MockLLMClient) GetDefaultModel() string {
	return "mock-model-1.0"
}

func (m *MockLLMClient) ValidateConfig() error {
	return nil
}

// Utility functions

func contains(s, substr string) bool {
	return len(s) > 0 && len(substr) > 0 && (s == substr || len(s) > len(substr) &&
		(s[:len(substr)] == substr || s[len(s)-len(substr):] == substr ||
			findInString(s, substr)))
}

func findInString(s, substr string) bool {
	for i := 0; i <= len(s)-len(substr); i++ {
		if s[i:i+len(substr)] == substr {
			return true
		}
	}
	return false
}

func printSchema(schema *schema_inference.DataSchema) {
	fmt.Printf("\nSchema: %s\n", schema.Name)
	fmt.Printf("Description: %s\n", schema.Description)
	fmt.Printf("Inferred at: %s\n", schema.InferredAt.Format("2006-01-02 15:04:05"))
	fmt.Printf("\nColumns (%d):\n", len(schema.Columns))

	for _, col := range schema.Columns {
		fmt.Printf("\n  Column: %s\n", col.Name)
		fmt.Printf("    Type: %s (%s)\n", col.DataType, col.OntologyType)
		fmt.Printf("    Description: %s\n", col.Description)

		if col.AIEnhanced {
			fmt.Printf("    AI Enhanced: Yes (confidence: %.2f)\n", col.AIConfidence)
		}

		if col.IsPrimaryKey {
			fmt.Printf("    Primary Key: Yes\n")
		}
		if col.IsRequired {
			fmt.Printf("    Required: Yes\n")
		}
		if col.IsUnique {
			fmt.Printf("    Unique: Yes\n")
		}

		if len(col.SampleValues) > 0 {
			samplesJSON, _ := json.Marshal(col.SampleValues)
			fmt.Printf("    Samples: %s\n", string(samplesJSON))
		}

		if len(col.Constraints) > 0 {
			fmt.Printf("    Constraints:\n")
			for key, value := range col.Constraints {
				fmt.Printf("      %s: %v\n", key, value)
			}
		}
	}

	if len(schema.Relationships) > 0 {
		fmt.Printf("\nRelationships (%d):\n", len(schema.Relationships))
		for _, rel := range schema.Relationships {
			fmt.Printf("  %s -> %s (%s, strength: %.2f)\n",
				rel.SourceColumn, rel.TargetColumn, rel.RelationshipType, rel.Strength)
		}
	}

	if len(schema.Metadata) > 0 {
		fmt.Printf("\nMetadata:\n")
		for key, value := range schema.Metadata {
			fmt.Printf("  %s: %v\n", key, value)
		}
	}
}
